{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb81c92",
   "metadata": {},
   "source": [
    "\n",
    "# Záróvizsga igazságossága"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3de0f",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3155dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60498374",
   "metadata": {},
   "source": [
    "Kiindulásképp azt gondoltam át, milyen adatokat érdemes kinyerni egy kész beosztásból. Az alábbiakat hasznosnak tartottam: \n",
    " 1. hány tárgyat tanít egy tanár   \n",
    " 2. az egyes tárgyakhoz hány tanár és hallgató jut -> átlagos hallgatók száma / tanár\n",
    " 3. vizsgáztatóként hányszor van beosztva (ennek számolja alapból)\n",
    " 4. elnökként hányszor van beosztva (ha nem vizsgázató)\n",
    " 5. tagként hányszor van beosztva (ha nem elnök)\n",
    " \n",
    "(*Alternatív megoldás a 3-5. pontokra:*  egy tanár egy beosztását elképzelhetjük egy 3 elemű vektorként, pl. `[1 0 1]` jelentheti, hogy a tanár vizsgáztatóként és tagként volt jelen. Én végül nem így dolgoztam fel a bemeneti fájlt, így arra a kérdésre nem tud a modellem válaszolni, hogy hányszor volt egy tanár egyszerre vizsgáztató és elnök. Azért gondolom, hogy ez felesleges lehet, mert a munkateher meghatározásához nem kellene kétszer beleszámolni ugyanazt a vizsgaalkalmat. Ha az igazságosság szempontjából mégis úgy döntünk, hogy munkateher szempontjából eltérő egy `[1 0 0]` és egy `[1 1 0]` eset, akkor a fájl feldolgozásakor ezt is tárolni kell.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc5fcb",
   "metadata": {},
   "source": [
    "Következő lépésben felállítottam egy példa adathalmazt, melyben az egyes oktatókhoz az alábbi értékeket rendeltem: \n",
    " - hány vizsgán vesznek részt vizsgáztatóként\n",
    " - hány tárgyat tanítanak\n",
    " - tárgyakra bontva a vizsgázóik száma\n",
    " - tárgyakra bontva a hallgatóik száma\n",
    "Pl. az alábbi számok jellemzik 3 tanár tárgyainak és vizsgázatott hallgatóinak számát. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8c5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {\"examines\": 34, \"total_courses\": 3, \"exams_per_course\": {1: 8, 2: 10, 3: 16}, \"students_per_course\": {1: 8, 2: 10, 3: 8}}\n",
    "B = {\"examines\": 17, \"total_courses\": 1, \"exams_per_course\": {0: 17}, \"students_per_course\": {0: 17}}\n",
    "C = {\"examines\": 4, \"total_courses\": 2, \"exams_per_course\": {3: 0, 4: 4}, \"students_per_course\": {3: 8, 4: 4}}\n",
    "\n",
    "df = pd.DataFrame([A, B, C], index = [\"A\", \"B\", \"C\"])\n",
    "df[\"spc_sum\"] = df.apply(lambda x: sum(x.students_per_course.values()), axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b20988d",
   "metadata": {},
   "source": [
    "Alább pedig az egyes tárgyakról található példaadat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "Courses = {0: {\"students\": 17, \"teachers\": 1}, \n",
    "           1: {\"students\": 8, \"teachers\": 1 }, \n",
    "           2: {\"students\": 10, \"teachers\": 1}, \n",
    "           3: {\"students\": 16, \"teachers\": 2}, \n",
    "           4: {\"students\": 4, \"teachers\": 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f7fec",
   "metadata": {},
   "source": [
    "Talán érezhető, hogy a \"C\" tanár az igazságosabbnál kevesebb vizsgára került beosztásra. \n",
    "A példa adathalmazban az `exams_per_course` és `students_per_course` oszlopok nem túl elegánsak, ráadásul az utóbbi még redundáns információkat is tartalmaz. Mindkettő igazából csak bizonyos másik értékek meghatározásához kell. Az alábbi modellben így ezeket az oszlopokat elhagytam. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeddf0ee",
   "metadata": {},
   "source": [
    "#### Problémafelvetés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367284be",
   "metadata": {},
   "source": [
    "A modellnek erőteljesen zárt világ feltételezése van. Ha egy tanár pl. más tárgyakat is tanít, de ez nem derül ki a beosztásból, ez a tény nem lesz figyelembe véve. Ugyanígy, csak akkor mondhatjuk bizonyossággal, hogy egy tanár betölthet pl. elnöki pozíciót, ha van olyan beosztás, ahol elnök. \n",
    "> **Javaslat:** A bemenetből az alábbi kérdésekre biztosabb választ találni. (Pl. az elérhetőségek lapon megtalálható, hogy ki lehet elnök/tag/titkár.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf57e1",
   "metadata": {},
   "source": [
    "Előfordulhat, hogy a modell aránytalanságokat talál, de a valóságban ez kívánt viselkedés. Pl. egy tárgyvezető nagyobb százalékban kíván jelen lenni a vizsgákon, mint a többi oktató. Ha a beosztás is ezt figyelembe véve lett elkészítve, akkor az igazságosság megállapításakor pl. súlyokkal tudjuk ezt az információt kezelni. Az általam implementált modell ezzel nem foglalkozik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5558869",
   "metadata": {},
   "source": [
    "### Input feldolgozása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4947b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "68305a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduleStats:\n",
    "    \n",
    "    _SCHEDULE_DATA_PATH = './data/Beosztáshoz2020osz.xlsx'\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._schedule = self.load_in_sample_data()\n",
    "        # The function below presupposes the initialized schedule dataframe\n",
    "        self.courses = self._init_courses()\n",
    "        # The function below presupposes the initialized schedule and courses dataframes \n",
    "        self.teachers = self._init_teachers()\n",
    "        \n",
    "    def load_in_sample_data(self):\n",
    "        path = ScheduleStats._SCHEDULE_DATA_PATH\n",
    "        sheet_name = '1.kör'\n",
    "        usecols = \"I:K,M:O,Q\"\n",
    "        \n",
    "        schedule = self._load_in_schedule(path, sheet_name, usecols)\n",
    "        \n",
    "        # resolve NaN due to merged cells        \n",
    "        schedule[['Elnök', 'Tag', 'Titkár']] = schedule[['Elnök', 'Tag', 'Titkár']].fillna(method = 'ffill')\n",
    "        \n",
    "        # filter out rows where student name is NaN        \n",
    "        schedule = schedule.dropna(subset = ['Név'])\n",
    "        return schedule\n",
    "        \n",
    "    def _load_in_schedule(self, path, sheet_name = None, usecols = None):            \n",
    "        return pd.read_excel(path, sheet_name = sheet_name, usecols = usecols)           \n",
    "    \n",
    "    def _init_courses(self):\n",
    "        if self._schedule is None:\n",
    "            raise Exception('Parsing course information was called before initializing a \"Schedule\" DataFrame to work with. ')\n",
    "        course_data = [\n",
    "            {\"Tárgy\": targy, \n",
    "             \"Hallgatók\": len(self._schedule[self._schedule[\"Vizsgatárgy\"] == targy]),\n",
    "             \"Tanárok\": len(self._schedule[self._schedule[\"Vizsgatárgy\"] == targy].Vizsgáztató.unique())}\n",
    "            for targy in self._schedule.Vizsgatárgy.unique()\n",
    "        ]\n",
    "        courses = pd.DataFrame(course_data)\n",
    "        # Egy tanárra jutó hallgatók száma\n",
    "        courses['ETJH'] = courses.Hallgatók / courses.Tanárok\n",
    "        courses.ETJH = courses.ETJH.round().astype(int)\n",
    "        return courses\n",
    "    \n",
    "    def _init_teachers(self, workload_weights = np.ones((4))):\n",
    "        if self._schedule is None:\n",
    "            raise Exception('Parsing teacher information was called before initializing a \"Schedule\" DataFrame to work with. ')\n",
    "        if self.courses is None:\n",
    "            raise Exception('')\n",
    "        all_teachers = pd.unique(self._schedule[[\"Vizsgáztató\", \"Elnök\", \"Tag\", \"Titkár\"]].values.ravel('K'))\n",
    "        teacher_data = list(defaultdict())\n",
    "        for teacher in all_teachers:\n",
    "            exam_count = len(self._schedule[self._schedule.Vizsgáztató == teacher])\n",
    "            pres_count = len(self._schedule[(self._schedule.Vizsgáztató != teacher) & (self._schedule.Elnök == teacher)])\n",
    "            mem_count = len(self._schedule[(self._schedule.Vizsgáztató != teacher) & (self._schedule.Tag == teacher)])\n",
    "            sec_count = len(self._schedule[(self._schedule.Vizsgáztató != teacher) & (self._schedule.Titkár == teacher)])\n",
    "            taught_courses = self._schedule[self._schedule.Vizsgáztató == teacher].Vizsgatárgy.unique()\n",
    "            # Taught courses index // (oktatott tárgyak index)\n",
    "            TCI = len(taught_courses)\n",
    "            # Cumulative student index (for the teached subjects) // (kumulatív hallgatók index)\n",
    "            CSI = sum(self.courses[self.courses.Tárgy.isin(taught_courses)].Hallgatók)\n",
    "            # Average students index (per teacher) // (átlagos hallgatók index)\n",
    "            ASI = sum(self.courses[self.courses.Tárgy.isin(taught_courses)].ETJH)\n",
    "            teacher_dict = {\"Név\": teacher, \n",
    "             \"Vizsga\": exam_count, \n",
    "             \"Elnök\": pres_count,\n",
    "             \"Tag\": mem_count,\n",
    "             \"Titkár\": sec_count,\n",
    "             \"OTI\": TCI,\n",
    "             \"KHI\": CSI,\n",
    "             \"ÁHI\": ASI,\n",
    "            }\n",
    "            teacher_data.append(teacher_dict)\n",
    "        return pd.DataFrame(teacher_data) \n",
    "    \n",
    "    def select_subset(name): \n",
    "        subset_loc = {\n",
    "            \"vizsgáztatók\": lambda df: (df[\"Vizsga\"] > 0),\n",
    "            \"egyéb\": lambda df: df[\"Vizsga\"] <= 0,\n",
    "        }\n",
    "\n",
    "        if name.lower() not in subset_loc.keys():\n",
    "            raise Exception(f'Subset \"{name}\" does not exist.')\n",
    "\n",
    "        return subset_loc[name.lower()]\n",
    "\n",
    "    def subset(teacher_df, name): \n",
    "        return teacher_df[ScheduleStats.select_subset(name)]\n",
    "\n",
    "    def workload(teacher_df, workload_weights = np.ones(4)):\n",
    "        col_subset = [\"Vizsga\", \"Elnök\", \"Tag\", \"Titkár\"]\n",
    "        wl = teacher_df[col_subset].apply(lambda df: np.dot(df, workload_weights).item(), axis = 1)   \n",
    "        wl.name = \"Munka\"\n",
    "        return wl\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf15ec",
   "metadata": {},
   "source": [
    "#### Az osztály használata: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73baa0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ScheduleStats()\n",
    "display(\"Schedule\", stats._schedule)\n",
    "display(\"Courses\", stats.courses)\n",
    "display(\"Teachers\", stats.teachers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d068be",
   "metadata": {},
   "source": [
    "### Regresszió"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032c66a9",
   "metadata": {},
   "source": [
    "Az alábbi fejezetben a sklearn regressziós modelljeit vetem össze. Ezen belül is megvizsgálom a lineáris regressziót, a polinomiális regressziót és a Support Vector regressziót. A determinációs együtthatón keresztül vizsgálom, hogy a modellek mennyire illeszkednek a beosztásból kinyert adatokhoz. \n",
    "A vizsgált dimenziók az oktatók oktatott tárgyainak száma (OTI), kumulált hallgatóinak száma (KHI) és átlagos hallgatóinak száma (ÁHI). Csak azokat az oktatókat vizsgálom most, akiknek ezen értékek legalább egyike nem 0. (A titkárok és a vizsgáztatók diszkrét halmazokat alkotnak a leírt feltétel szerint, a titkárok egyáltalán nem jelennek meg vizsgáztatói szerepben, így a vizsgált indexek minden esetben nullát vesznek fel az esetükben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb016950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4f5e06",
   "metadata": {},
   "source": [
    "A szükséges importálások után előállítom a modell bemeneti és kimeneti értékeit a feljebb kifejtett indexekre való projekcióval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dded5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ScheduleStats()\n",
    "input_columns = ['OTI', 'KHI', 'ÁHI']\n",
    "data = stats.teachers[(stats.teachers[input_columns] != 0).all(axis = 1)]\n",
    "\n",
    "X, y = data[input_columns], ScheduleStats.workload(data, np.ones(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d989c",
   "metadata": {},
   "source": [
    "Első körben a lineáris regressziót figyelem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20a9c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² =  0.3582615792721434\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression().fit(X,y)\n",
    "print(\"R\\u00b2 = \", model.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b04506",
   "metadata": {},
   "source": [
    "Ezt követően a polinomiális regressziót vizsgálom. Ez lényegesen jobb eredményt ér el. \n",
    "A később vizsgált modellek ennél gyengébb determinációs együtthatót érnek el, így egyúttal egy táblázatban demonstrálom azt is, hogy az adott bemeneti és kimeneti értékekhez a modell milyen munkaterhet jósol egy oktatónak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a315132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(degree = 2, include_bias = False), LinearRegression()).fit(X, y)\n",
    "print(\"R\\u00b2 = \", model.score(X, y))\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "print(\"Prediction: \")\n",
    "\n",
    "np_pred = np.array((X.OTI, X.KHI, X.ÁHI, y, y_pred.round(2)))\n",
    "pd.DataFrame(np_pred.T, columns = [\"OTI\", \"KHI\", \"ÁHI\", \"Actual workload\", \"Prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782347e6",
   "metadata": {},
   "source": [
    "A szemléltetés érdekében az alábbi két diagramot rajzoltatom ki. Természetesen egy 4 dimenziós modellt 3 dimenzióban nem lehet teljesen megérteni, ezzel indoklom a nagyon furcsa regressziós görbét."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1a416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.ÁHI, y)\n",
    "plt.plot(X.ÁHI, y_pred, 'r')\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca841a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(X.KHI, X.ÁHI, y);\n",
    "ax.plot(X.KHI, X.ÁHI, y_pred, \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d251e2",
   "metadata": {},
   "source": [
    "Végül a Support Vector Machines alá tartozó Support Vector Regression osztályt vizsgáltam. Ezen belül három kernel módot próbáltam ki, ezek a Radial basis function, Lineáris és Polinom. Mindhárom módot skálázással és anélkül is vizsgáltam.\n",
    "Míg az RBF esetében a skálázás rontott az eredményen, a Polinomnál 10%-ot javított. (A lineáris módnál nem változott, hiszen a skálázás maga is egy lineáris művelet.) Az RBF (skálázás nélkül) érte el a legmagasabb determinációs együttható értéket (0.3689). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf = svm.SVR(kernel=\"rbf\", C=100, gamma=0.1, epsilon=0.1)\n",
    "svr_lin = svm.SVR(kernel=\"linear\", C=100, gamma=\"auto\")\n",
    "svr_poly = svm.SVR(kernel=\"poly\", C=100, gamma=\"auto\", degree=3, epsilon=0.1, coef0=1)\n",
    "models = [(\"RBF\", svr_rbf), (\"LIN\", svr_lin), (\"POLY\", svr_poly)]\n",
    "print(\"Models without scaling: \")\n",
    "for name, model in models:\n",
    "    model.fit(X, y)\n",
    "    print(\"R\\u00b2 of %s = %s\" % (name, model.score(X, y)))\n",
    "    \n",
    "print(\"Models with scaling: \")\n",
    "for name, model in models:\n",
    "    ppl = make_pipeline(StandardScaler(), model)\n",
    "    ppl.fit(X, y)\n",
    "    print(\"R\\u00b2 of %s = %s\" %(name, ppl.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e8e128",
   "metadata": {},
   "source": [
    "### Igazságosság"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f03b58f",
   "metadata": {},
   "source": [
    "Most, hogy elő tudjuk állítani a releváns bemeneti adatokat és van némi tapasztalatunk pár regressziós modellel, ideje megválaszolni az eredeti kérdést: igazságos-e a beosztás. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36ecdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f69d4f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FairnessChecker:\n",
    "    \n",
    "    SAVED_DATASET = './data/schedule_dataset.pickle'\n",
    "    \n",
    "    def _load_pickled(self, path):\n",
    "        with open(path, mode = 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        \n",
    "    def _pickle_obj(self, obj, path):\n",
    "        with open(path, mode = 'wb') as f:\n",
    "            pickle.dump(obj, f)\n",
    "        \n",
    "    def _init_dataset(self, force_reload):\n",
    "        path = FairnessChecker.SAVED_DATASET\n",
    "        \n",
    "        if os.path.exists(path) and not force_reload:\n",
    "            self.dataset = self._load_pickled(path)\n",
    "        else:\n",
    "            self.dataset = ScheduleStats()\n",
    "            self._pickle_obj(self.dataset, path)        \n",
    "            \n",
    "    def default_model(): \n",
    "        default_poly_degree = 2\n",
    "        pipeline = Pipeline([\n",
    "            (\"polynomial_features\", PolynomialFeatures(degree = default_poly_degree, include_bias = False)), \n",
    "            (\"linear_regression\", LinearRegression()),\n",
    "        ])\n",
    "        return pipeline\n",
    "    \n",
    "    def __init__(self, model = default_model, force_reload = False):\n",
    "        if callable(model):\n",
    "            self.model = model()\n",
    "        else:\n",
    "            self.model = model\n",
    "        self._init_dataset(force_reload)\n",
    "        \n",
    "    def train_test(self, \n",
    "                   select = True, \n",
    "                   project = [\"Elnök\", \"Tag\", \"Titkár\", \"OTI\", \"KHI\", \"ÁHI\"], \n",
    "                   aggregate = None,\n",
    "                   workload_weights = np.ones(4)):\n",
    "        df = self.dataset.teachers\n",
    "        if aggregate:\n",
    "            aggr_from, aggr_to, aggr_lam = aggregate\n",
    "            df[aggr_to] = df[aggr_from].apply(aggr_lam, axis = 1)\n",
    "        df = df[select]\n",
    "        wl = ScheduleStats.workload(df, workload_weights)\n",
    "        return df[project], wl\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def _examiner_fair_check():\n",
    "        checker = FairnessChecker()    \n",
    "        teacher_selection = ScheduleStats.select_subset(\"vizsgáztatók\")\n",
    "        X, y = checker.train_test(\n",
    "            select = teacher_selection,\n",
    "            project = [\"Extra\", \"OTI\", \"KHI\", \"ÁHI\"],\n",
    "            aggregate = ([\"Elnök\", \"Tag\", \"Titkár\"], \"Extra\", lambda df: df.sum()),\n",
    "            workload_weights = (1., 0., 0., 0.),\n",
    "        )\n",
    "        checker.fit(X, y)\n",
    "        y_pred = pd.Series(checker.predict(X).round(2), name = \"Pred\")\n",
    "        return pd.concat([y, y_pred], axis = 1)\n",
    "        \n",
    "    def _others_fair_check(checker = FairnessChecker()):\n",
    "        X = ScheduleStats.subset(checker.dataset.teachers, \"egyéb\")\n",
    "        y = ScheduleStats.workload(X, workload_weights = (0, 1, 1, 1))\n",
    "        y_pred = pd.Series(round(np.mean(y),2), index = y.index, name = \"Pred\")\n",
    "        return pd.concat([y, y_pred], axis = 1)\n",
    "    \n",
    "    def fair_check(threshold = 1.0):\n",
    "        checker = FairnessChecker()\n",
    "\n",
    "        examiners_df = FairnessChecker._examiner_fair_check()\n",
    "        others_df = FairnessChecker._others_fair_check(checker)\n",
    "        fairness_df = examiners_df.append(others_df)\n",
    "        fairness_df = pd.concat([checker.dataset.teachers[\"Név\"], fairness_df], axis = 1)\n",
    "\n",
    "        scaler = StandardScaler(with_mean = False)\n",
    "        fairness_df[\"Std_Pred\"] = (fairness_df.Munka - fairness_df.Pred)**2\n",
    "        fairness_df[\"Std_Pred\"] = scaler.fit_transform(fairness_df[\"Std_Pred\"].values.reshape((-1,1))).round(2)\n",
    "        return fairness_df[fairness_df.Std_Pred > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f6f695cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A beosztás a modell szerint az alábbi oktatók esetén nem volt igazságos:  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Név</th>\n",
       "      <th>Munka</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Std_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr. Dudás Ákos</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.88</td>\n",
       "      <td>2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imre Gábor</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.88</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dr. Kovács Tibor</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Kovács László</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dr. Nagy Ákos</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sik Tamás Dávid</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Veréb Szabolcs</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.39</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Név  Munka   Pred  Std_Pred\n",
       "0     Dr. Dudás Ákos   23.0  13.88      2.76\n",
       "1         Imre Gábor    6.0  13.88      2.06\n",
       "22  Dr. Kovács Tibor   21.0  10.39      3.74\n",
       "30     Kovács László    1.0  10.39      2.93\n",
       "33     Dr. Nagy Ákos    4.0  10.39      1.36\n",
       "35   Sik Tamás Dávid   21.0  10.39      3.74\n",
       "36    Veréb Szabolcs   16.0  10.39      1.04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unfair_results = FairnessChecker.fair_check()\n",
    "if unfair_results.empty: \n",
    "    print(\"A beosztás a modell szerint igazságos! :-) \")\n",
    "else:\n",
    "    print(\"A beosztás a modell szerint az alábbi oktatók esetén nem volt igazságos:  \")\n",
    "    display(unfair_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527e91c",
   "metadata": {},
   "source": [
    "## Lehetséges fejlesztési irányok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac7a95",
   "metadata": {},
   "source": [
    "Feltehetően nem lesz ugyanolyan sémájú az összes bemeneti excel fájlunk. `A ScheduleStats` osztály jelen formájában egy konkrét bemeneti fájlból indul ki. Érdemes lehet a beolvasott fájl feldolgozását lambda függvényeken keresztül elvégezni és a mostani, fájlspecifikus feldolgozást alapértelmezettként kezelni. Alternatíva lehet egy leszármazott osztályban implementálni az összes, a 2020-as bemeneti Excel fájlra jellemző feldolgozást, így növelve a kód újrafelhasználhatóságát.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a77aa9",
   "metadata": {},
   "source": [
    "A kód követhetősége érdekében érdemes lehet áttérni mindenhol az angol terminológiára. A DataFramek oszlopnevei egyelőre szimplán átveszik a beolvasott fájl fejléceit, így a kódban is sok helyen zavaró lehet a magyar. (Másrészről viszont igaz, hogy a kód teljes egészében a BME-VIK záróvizsgabeosztásainak igazságosságával foglalkozik, helyénvaló lehet meghagyni változatlanul az oszlopokat.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
